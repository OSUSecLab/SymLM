import json
import argparse

def get_top_prob(prediction, probability, prob_threshold=0.5):
    preds = prediction.split(' ')
    # preds = preds[:topK]
    probs = probability.replace('[', '').replace(']', '')
    probs = probs.split(' ')
    res = []
    for i, prob in enumerate(probs):
        prob = float(prob)
        if prob >= prob_threshold:
            res.append(preds[i])
    if len(res) == 0:
        res = preds[:1]
    return ' '.join(res)

def split_words(line):
    return line.lower().strip().split(' ')

def get_correct_predictions_word_cluster(target, prediction, word_cluster):
    """
    Calculate predictions based on word cluster generated by CodeWordNet.
    """
    true_positive, false_positive, false_negative = 0, 0, 0
    replacement = dict()
    skip = set()
    for j, p in enumerate(prediction):
        if p in target:
            skip.add(j)
    for i, t in enumerate(target):
        for j, p in enumerate(prediction):
            if t != p and j not in replacement and j not in skip:
                if t in word_cluster and p in word_cluster:
                    t_cluster = word_cluster[t]
                    p_cluster = word_cluster[p]
                    t_cluster, p_cluster = set(t_cluster), set(p_cluster)
                    if len(t_cluster.intersection(p_cluster)) > 0:
                        replacement[j] = t
    for k, v in replacement.items():
        prediction[k] = v
    if target == prediction:
        true_positive = len(target)
    else:
        target = set(target)
        prediction = set(prediction)

        true_positive += len(target.intersection(prediction))
        false_negative += len(target.difference(prediction))
        false_positive += len(prediction.difference(target))
    return true_positive, false_positive, false_negative

def calculate_results(true_positive, false_positive, false_negative):
    # avoid dev by 0
    if true_positive + false_positive == 0:
        return 0, 0, 0
    precision = true_positive / (true_positive + false_positive)
    recall = true_positive / (true_positive + false_negative)
    if precision + recall > 0:
        f1 = 2 * precision * recall / (precision + recall)
    else:
        f1 = 0
    return precision, recall, f1

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--evaluation-input', type=str, 
                     help='Path to the evaluation input file')
    parser.add_argument('--prob-threshold', type=float, default=0.3,
                        help='Probability threshold for selecting the predicted words')
    args = parser.parse_args()
    input_file = args.evaluation_input

    with open("training_evaluation/prediction_evaluation/word_cluster.json", 'r') as f:
        word_cluster = json.load(f)

    true_positive, false_positive, false_negative = 0, 0, 0
    total = 0
    targets = []
    predictions = []
    threshold = args.prob_threshold
    with open(input_file, 'r') as f:
        for i, line in enumerate(f):
            total += 1
            line = line.strip('\n')
            lines = line.split(',')
            lines[1] = get_top_prob(lines[1], lines[2], prob_threshold=threshold)
            assert isinstance(lines[1], str) and len(lines[1]) > 0, "Don't give empty prediction"
            targets.append(lines[0])
            predictions.append(lines[1])
            target = split_words(lines[0])
            prediction = split_words(lines[1])
            tp, fp, fn = get_correct_predictions_word_cluster(target, prediction, word_cluster)
            true_positive += tp
            false_positive += fp
            false_negative += fn
    precision, recall, f1 = calculate_results(true_positive, false_positive, false_negative)
    print(
        "Probability Threshold = {}, Precision: {}, Recall: {}, F1: {}".format(threshold, precision, recall,
                                                                                 f1))

if __name__ == '__main__':
    main()